{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa08a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f113dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c739ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4625d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"gemma3\",\n",
    "                 base_url=\"http://localhost:11434\",\n",
    "                 temperature=0,\n",
    "                 num_predict=1024,\n",
    "                 num_ctx=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d9bb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gemma3', num_ctx=2048, num_predict=1024, temperature=0.0, base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c129950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is LangChain?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages =[\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is LangChain?\")\n",
    "]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1ae8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e9ed78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, let's break down what LangChain is. It’s a really exciting and rapidly evolving framework designed to make it much easier to build applications powered by large language models (LLMs) like GPT-3, GPT-4, Claude, and others.\\n\\nHere's a breakdown of key aspects:\\n\\n**1. What it is:**\\n\\n* **A Framework, Not a Model:** It’s crucial to understand that LangChain isn't a language model itself. It’s a toolkit – a collection of components and abstractions – that helps you *connect* LLMs to other data sources and tools. Think of it like a LEGO set for building LLM-powered applications.\\n* **Simplifies LLM Development:** Building applications with LLMs can be complex. You need to handle things like:\\n    * **Prompt Engineering:** Crafting the right prompts to get the LLM to do what you want.\\n    * **Data Retrieval:**  LLMs have a limited amount of knowledge. You often need to feed them relevant information from external sources.\\n    * **Chaining Together Operations:**  You might want to perform multiple steps – like retrieving information, summarizing it, and then answering a user's question.\\n    * **Memory:**  LLMs are stateless, so you need ways to maintain context across multiple interactions.\\n\\nLangChain provides pre-built components and abstractions to handle all of these challenges.\\n\\n\\n**2. Key Components & Concepts:**\\n\\n* **Models:**  Interfaces for interacting with different LLMs.  It abstracts away the specifics of each model, so you can easily switch between them.\\n* **Prompts:**  LangChain provides tools for creating, managing, and optimizing prompts.\\n* **Chains:** The core concept! Chains are sequences of calls to LLMs or other utilities. They're how you build complex workflows.  Examples:\\n    * **LLMChain:** The most basic chain – it just calls an LLM with a prompt.\\n    * **RetrievalQA Chain:**  Combines a retrieval system (like a vector database) with an LLM to answer questions based on retrieved documents.\\n* **Document Loaders:**  Tools for loading data from various sources (PDFs, websites, databases, etc.) into a format that LLMs can understand.\\n* **Vector Stores:**  Databases optimized for storing and searching vector embeddings – numerical representations of text.  This is essential for RetrievalQA chains.\\n* **Memory:**  Components for adding conversational memory to your applications.  This allows the LLM to remember previous interactions.\\n\\n**3. What it's Used For:**\\n\\nLangChain is used to build a *huge* range of applications, including:\\n\\n* **Question Answering Systems:**  Answering questions based on your own data.\\n* **Chatbots:**  More sophisticated chatbots that can maintain context and access external information.\\n* **Agents:**  Systems that can autonomously perform tasks by using LLMs and tools. (Think of an agent that can book a flight for you).\\n* **Data Analysis:**  Extracting insights from data using LLMs.\\n* **Content Generation:**  Creating different types of content (summaries, articles, code, etc.).\\n\\n\\n\\n**4. Resources to Learn More:**\\n\\n* **Official LangChain Website:** [https://www.langchain.com/](https://www.langchain.com/) - This is the best place to start.\\n* **LangChain Documentation:** [https://python.langchain.com/](https://python.langchain.com/) -  Detailed documentation and tutorials.\\n* **LangChain Examples:** [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain) - Explore example code.\\n\\n---\\n\\n**Do you want me to delve deeper into a specific aspect of LangChain, such as:**\\n\\n*   A particular component (e.g., Chains, Document Loaders)?\\n*   A specific use case (e.g., building a question-answering system)?\\n*   The underlying concepts (e.g., embeddings, vector databases)?\", additional_kwargs={}, response_metadata={'model': 'gemma3', 'created_at': '2025-12-08T07:23:22.112731Z', 'done': True, 'done_reason': 'stop', 'total_duration': 29879536333, 'load_duration': 110340041, 'prompt_eval_count': 25, 'prompt_eval_duration': 1292742667, 'eval_count': 867, 'eval_duration': 28475973666, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run--9b7c520a-aed1-4bd5-9ad7-bdc8f9e33eee-0', usage_metadata={'input_tokens': 25, 'output_tokens': 867, 'total_tokens': 892})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed8899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Okay, let's break down what LangChain is. It’s a really exciting and rapidly evolving framework designed to make it much easier to build applications powered by large language models (LLMs) like GPT-3, GPT-4, Claude, and others.\n",
      "\n",
      "Here's a breakdown of key aspects:\n",
      "\n",
      "**1. What it is:**\n",
      "\n",
      "* **A Framework, Not a Model:** It’s crucial to understand that LangChain isn't a language model itself. It’s a toolkit – a collection of components and abstractions – that helps you *connect* LLMs to other data sources and tools. Think of it like a LEGO set for building LLM-powered applications.\n",
      "* **Simplifies LLM Development:** Building applications with LLMs can be complex. You need to handle things like:\n",
      "    * **Prompt Engineering:** Crafting the right prompts to get the LLM to do what you want.\n",
      "    * **Data Retrieval:**  LLMs have a limited amount of knowledge. You often need to feed them relevant information from external sources.\n",
      "    * **Chaining Together Operations:**  You might want to perform multiple steps – like retrieving information, summarizing it, and then answering a user's question.\n",
      "    * **Memory:**  LLMs are stateless, so you need ways to maintain context across multiple interactions.\n",
      "\n",
      "LangChain provides pre-built components and abstractions to handle all of these challenges.\n",
      "\n",
      "\n",
      "**2. Key Components & Concepts:**\n",
      "\n",
      "* **Models:**  Interfaces for interacting with different LLMs.  It abstracts away the specifics of each model, so you can easily switch between them.\n",
      "* **Prompts:**  LangChain provides tools for creating, managing, and optimizing prompts.\n",
      "* **Chains:** The core concept! Chains are sequences of calls to LLMs or other utilities. They're how you build complex workflows.  Examples:\n",
      "    * **LLMChain:** The most basic chain – it just calls an LLM with a prompt.\n",
      "    * **RetrievalQA Chain:**  Combines a retrieval system (like a vector database) with an LLM to answer questions based on retrieved documents.\n",
      "* **Document Loaders:**  Tools for loading data from various sources (PDFs, websites, databases, etc.) into a format that LLMs can understand.\n",
      "* **Vector Stores:**  Databases optimized for storing and searching vector embeddings – numerical representations of text.  This is essential for RetrievalQA chains.\n",
      "* **Memory:**  Components for adding conversational memory to your applications.  This allows the LLM to remember previous interactions.\n",
      "\n",
      "**3. What it's Used For:**\n",
      "\n",
      "LangChain is used to build a *huge* range of applications, including:\n",
      "\n",
      "* **Question Answering Systems:**  Answering questions based on your own data.\n",
      "* **Chatbots:**  More sophisticated chatbots that can maintain context and access external information.\n",
      "* **Agents:**  Systems that can autonomously perform tasks by using LLMs and tools. (Think of an agent that can book a flight for you).\n",
      "* **Data Analysis:**  Extracting insights from data using LLMs.\n",
      "* **Content Generation:**  Creating different types of content (summaries, articles, code, etc.).\n",
      "\n",
      "\n",
      "\n",
      "**4. Resources to Learn More:**\n",
      "\n",
      "* **Official LangChain Website:** [https://www.langchain.com/](https://www.langchain.com/) - This is the best place to start.\n",
      "* **LangChain Documentation:** [https://python.langchain.com/](https://python.langchain.com/) -  Detailed documentation and tutorials.\n",
      "* **LangChain Examples:** [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain) - Explore example code.\n",
      "\n",
      "---\n",
      "\n",
      "**Do you want me to delve deeper into a specific aspect of LangChain, such as:**\n",
      "\n",
      "*   A particular component (e.g., Chains, Document Loaders)?\n",
      "*   A specific use case (e.g., building a question-answering system)?\n",
      "*   The underlying concepts (e.g., embeddings, vector databases)?\n"
     ]
    }
   ],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa5013",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af01fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "527b057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['audience', 'subject', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['audience', 'subject'], input_types={}, partial_variables={}, template='You are an expert in {subject}. Explain it to a {audience} students.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Can you explain {topic}?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an expert in {subject}. Explain it to a {audience} students.\"),\n",
    "    (\"human\",\"Can you explain {topic}?\")]\n",
    "\n",
    "    )\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2773db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are an expert in artificial intelligence. Explain it to a high school students.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you explain large language models?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = prompt.invoke({\n",
    "    \"subject\":\"artificial intelligence\",\n",
    "    \"audience\":\"high school\",\n",
    "    \"topic\":\"large language models\"})\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec91b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66788dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Okay, let’s talk about Large Language Models – they’re a *huge* deal in the world of AI right now, and frankly, they’re pretty mind-blowing. Think of them as super-smart parrots, but instead of just repeating what they hear, they can actually *generate* new text that sounds remarkably human. \n",
      "\n",
      "Here’s the breakdown, broken down into digestible chunks:\n",
      "\n",
      "**1. What *are* Large Language Models?**\n",
      "\n",
      "* **They’re Computer Programs:** At their core, they’re just really complex computer programs, built using something called **artificial neural networks**.  Don't let the jargon scare you. Think of a neural network like a massively interconnected web of switches.\n",
      "* **“Large” Means Big Data:** The “Large” part comes from the *amount* of text they’ve been trained on. These models have been fed *massive* amounts of data – basically, almost the entire internet! This includes books, articles, websites, code, social media posts… you name it.\n",
      "* **Language Models:** They’re called “language models” because they’ve learned to predict the *next word* in a sequence.  That’s it!  It sounds simple, but when you do it billions of times with enough data, it creates incredibly sophisticated understanding of language.\n",
      "\n",
      "\n",
      "**2. How Do They Work? (Simplified!)**\n",
      "\n",
      "* **Pattern Recognition:**  Imagine you’re learning a new language. You start noticing patterns – how words are used together, what sounds common, etc.  LLMs do the same thing, but on a *massive* scale.\n",
      "* **Probability:** They don't \"understand\" language in the way a human does. Instead, they calculate the *probability* of a word appearing after a given sequence of words.  For example, after the phrase \"The cat sat on the...\", the model will likely predict words like \"mat,\" \"chair,\" or \"sofa\" with high probability.\n",
      "* **“Transformers” – The Secret Sauce:**  Most modern LLMs use something called a “transformer” architecture. This is a clever design that allows the model to pay attention to *different parts* of the input text, understanding context much better. Think of it like highlighting the most important words in a sentence to understand its meaning.\n",
      "\n",
      "**3. Examples You've Probably Encountered:**\n",
      "\n",
      "* **ChatGPT:** This is probably the most famous example. It’s a chatbot that can answer your questions, write stories, translate languages, and even generate code.\n",
      "* **Google’s Bard:** Similar to ChatGPT, Bard is a conversational AI.\n",
      "* **Tools in other Apps:** LLMs are quietly powering features in many apps – like auto-completion in your email, translation tools, and even some search engines.\n",
      "\n",
      "\n",
      "**4. What They *Can’t* Do (Important Caveats!)**\n",
      "\n",
      "* **They Don’t Truly Understand:**  They’re incredibly good at *mimicking* understanding, but they don’t actually have consciousness or genuine comprehension. They're just really good at predicting patterns.\n",
      "* **They Can Make Mistakes:** Because they’re based on probability, they can sometimes generate incorrect or nonsensical information. This is often called “hallucination.”\n",
      "* **Bias:**  Because they’re trained on data created by humans, they can inherit and amplify existing biases in that data.\n",
      "\n",
      "**5. The Future is Exciting (and a Little Uncertain)**\n",
      "\n",
      "Large language models are still in their early stages of development, and they’re evolving incredibly quickly. They have the potential to revolutionize many industries, from education and healthcare to entertainment and business. \n",
      "\n",
      "**Resources to Learn More:**\n",
      "\n",
      "* **OpenAI’s Blog:** [https://openai.com/blog](https://openai.com/blog)\n",
      "* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "**Do you want me to delve deeper into a specific aspect of Large Language Models, such as:**\n",
      "\n",
      "*   How they’re trained?\n",
      "*   The ethical concerns surrounding them?\n",
      "*   A specific example like ChatGPT in more detail?\n"
     ]
    }
   ],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41672b16",
   "metadata": {},
   "source": [
    "## Langchain expression language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23060ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['audience', 'subject', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['audience', 'subject'], input_types={}, partial_variables={}, template='You are an expert in {subject}. Explain it to a {audience} students.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Can you explain {topic}?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd2165e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gemma3', num_ctx=2048, num_predict=1024, temperature=0.0, base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67b31279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke -> Langchain runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0e47718",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "193b7c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['audience', 'subject', 'topic'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['audience', 'subject'], input_types={}, partial_variables={}, template='You are an expert in {subject}. Explain it to a {audience} students.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Can you explain {topic}?'), additional_kwargs={})])\n",
       "| ChatOllama(model='gemma3', num_ctx=2048, num_predict=1024, temperature=0.0, base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15d913c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"subject\":\"artificial intelligence\",\n",
    "                      \"audience\":\"high school\",\n",
    "                      \"topic\":\"large language models\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47a8741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Okay, let’s talk about Large Language Models – they’re a *huge* deal in the world of AI right now, and frankly, they’re pretty mind-blowing. Think of them as super-smart parrots, but instead of just repeating what they hear, they can actually *generate* new text that sounds remarkably human. \n",
      "\n",
      "Here’s the breakdown, broken down into digestible chunks:\n",
      "\n",
      "**1. What *are* Large Language Models?**\n",
      "\n",
      "* **They’re Computer Programs:** At their core, they’re just really complex computer programs, built using something called **artificial neural networks**.  Don't let the jargon scare you. Think of a neural network like a massively interconnected web of switches.\n",
      "* **“Large” Means Big Data:** The “Large” part comes from the *amount* of text they’ve been trained on. These models have been fed *massive* amounts of data – basically, almost the entire internet! This includes books, articles, websites, code, social media posts… you name it.\n",
      "* **Language Models:** They’re called “language models” because they’ve learned to predict the *next word* in a sequence.  That’s it!  It sounds simple, but when you do it billions of times with enough data, it creates incredibly sophisticated understanding of language.\n",
      "\n",
      "\n",
      "**2. How Do They Work? (Simplified!)**\n",
      "\n",
      "* **Pattern Recognition:**  Imagine you’re learning a new language. You start noticing patterns – how words are used together, what sounds common, etc.  LLMs do the same thing, but on a *massive* scale.\n",
      "* **Probability:** They don't \"understand\" language in the way a human does. Instead, they calculate the *probability* of a word appearing after a given sequence of words.  For example, after the phrase \"The cat sat on the...\", the model will likely predict words like \"mat,\" \"chair,\" or \"sofa\" with high probability.\n",
      "* **“Transformers” – The Secret Sauce:**  Most modern LLMs use something called a “transformer” architecture. This is a clever design that allows the model to pay attention to *different parts* of the input text, understanding context much better. Think of it like highlighting the most important words in a sentence to understand its meaning.\n",
      "\n",
      "**3. Examples You've Probably Encountered:**\n",
      "\n",
      "* **ChatGPT:** This is probably the most famous example. It’s a chatbot that can answer your questions, write stories, translate languages, and even generate code.\n",
      "* **Google’s Bard:** Similar to ChatGPT, Bard is a conversational AI.\n",
      "* **Tools in other Apps:** LLMs are quietly powering features in many apps – like auto-completion in your email, translation tools, and even some search engines.\n",
      "\n",
      "\n",
      "**4. What They *Can’t* Do (Important Caveats!)**\n",
      "\n",
      "* **They Don’t Truly Understand:**  They’re incredibly good at *mimicking* understanding, but they don’t actually have consciousness or genuine comprehension. They're just really good at predicting patterns.\n",
      "* **They Can Make Mistakes:** Because they’re based on probability, they can sometimes generate incorrect or nonsensical information. This is often called “hallucination.”\n",
      "* **Bias:**  Because they’re trained on data created by humans, they can inherit and amplify existing biases in that data.\n",
      "\n",
      "**5. The Future is Exciting (and a Little Uncertain)**\n",
      "\n",
      "Large language models are still in their early stages of development, and they’re evolving incredibly quickly. They have the potential to revolutionize many industries, from education and healthcare to entertainment and business. \n",
      "\n",
      "**Resources to Learn More:**\n",
      "\n",
      "* **OpenAI’s Blog:** [https://openai.com/blog](https://openai.com/blog)\n",
      "* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "**Do you want me to delve deeper into a specific aspect of Large Language Models, such as:**\n",
      "\n",
      "*   How they’re trained?\n",
      "*   The ethical concerns surrounding them?\n",
      "*   A specific example like ChatGPT in more detail?\n"
     ]
    }
   ],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cecf95",
   "metadata": {},
   "source": [
    "## Adding Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee69b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8127bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f2b4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"subject\":\"artificial intelligence\",\n",
    "                      \"audience\":\"high school\",\n",
    "                      \"topic\":\"large language models\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76bfd6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, let’s talk about Large Language Models – they’re a *huge* deal in the world of AI right now, and frankly, they’re pretty mind-blowing. Think of them as super-smart parrots, but instead of just repeating what they hear, they can actually *generate* new text that sounds remarkably human. \\n\\nHere’s the breakdown, broken down into digestible chunks:\\n\\n**1. What *are* Large Language Models?**\\n\\n* **They’re Computer Programs:** At their core, they’re just really complex computer programs, built using something called **artificial neural networks**.  Don\\'t let the jargon scare you. Think of a neural network like a massively interconnected web of switches.\\n* **“Large” Means Big Data:** The “Large” part comes from the *amount* of text they’ve been trained on. These models have been fed *massive* amounts of data – basically, almost the entire internet! This includes books, articles, websites, code, social media posts… you name it.\\n* **Language Models:** They’re called “language models” because they’ve learned to predict the *next word* in a sequence.  That’s it!  It sounds simple, but when you do it billions of times with enough data, it creates incredibly sophisticated understanding of language.\\n\\n\\n**2. How Do They Work? (Simplified!)**\\n\\n* **Pattern Recognition:**  Imagine you’re learning a new language. You start noticing patterns – how words are used together, what sounds common, etc.  LLMs do the same thing, but on a *massive* scale.\\n* **Probability:** They don\\'t \"understand\" language in the way a human does. Instead, they calculate the *probability* of a word appearing after a given sequence of words.  For example, after the phrase \"The cat sat on the...\", the model will likely predict words like \"mat,\" \"chair,\" or \"sofa\" with high probability.\\n* **“Transformers” – The Secret Sauce:**  Most modern LLMs use something called a “transformer” architecture. This is a clever design that allows the model to pay attention to *different parts* of the input text, understanding context much better. Think of it like highlighting the most important words in a sentence to understand its meaning.\\n\\n**3. Examples You\\'ve Probably Encountered:**\\n\\n* **ChatGPT:** This is probably the most famous example. It’s a chatbot that can answer your questions, write stories, translate languages, and even generate code.\\n* **Google’s Bard:** Similar to ChatGPT, Bard is a conversational AI.\\n* **Tools in other Apps:** LLMs are quietly powering features in many apps – like auto-completion in your email, translation tools, and even some search engines.\\n\\n\\n**4. What They *Can’t* Do (Important Caveats!)**\\n\\n* **They Don’t Truly Understand:**  They’re incredibly good at *mimicking* understanding, but they don’t actually have consciousness or genuine comprehension. They\\'re just really good at predicting patterns.\\n* **They Can Make Mistakes:** Because they’re based on probability, they can sometimes generate incorrect or nonsensical information. This is often called “hallucination.”\\n* **Bias:**  Because they’re trained on data created by humans, they can inherit and amplify existing biases in that data.\\n\\n**5. The Future is Exciting (and a Little Uncertain)**\\n\\nLarge language models are still in their early stages of development, and they’re evolving incredibly quickly. They have the potential to revolutionize many industries, from education and healthcare to entertainment and business. \\n\\n**Resources to Learn More:**\\n\\n* **OpenAI’s Blog:** [https://openai.com/blog](https://openai.com/blog)\\n* **Google AI Blog:** [https://ai.googleblog.com/](https://ai.googleblog.com/)\\n\\n\\n---\\n\\n**Do you want me to delve deeper into a specific aspect of Large Language Models, such as:**\\n\\n*   How they’re trained?\\n*   The ethical concerns surrounding them?\\n*   A specific example like ChatGPT in more detail?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d3f43",
   "metadata": {},
   "source": [
    "## Streaming response and Structured Output (Pydantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8426bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf84696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(BaseModel):\n",
    "    sentiment:bool = Field(..., description=\"True if the sentiment is positive, False otherwise\")\n",
    "    reasoning: str = Field(..., description=\"The reasoning behind the sentiment\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86ad8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = ChatOllama(\n",
    "    model=\"llama3.2\",                 # now this model exists\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0,\n",
    "    num_predict=1024,\n",
    "    num_ctx=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a26bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm2.with_structured_output(Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a66784",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = structured_llm.invoke(\"I love programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5107125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sentiment\":true,\"reasoning\":\"love of programming\"}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3db9b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': True, 'reasoning': 'love of programming'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a16b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment=True reasoning='love of programming'"
     ]
    }
   ],
   "source": [
    "for chunk in structured_llm.stream(\"I love programming\"):\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a93b6185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sun-kissed fields of green and gold,\n",
      "The crack of will and gold,\n",
      "The crack of willow, stories unfold.\n",
      "A game ofow, stories unfold.\n",
      "A game of skill, of strength and might,\n",
      "Cr skill, of strength and might,\n",
      "Cricket's magic, shining bright.\n",
      "\n",
      "Theicket's magic, shining bright.\n",
      "\n",
      "The bowler runs, the batsman stands bowler runs, the batsman stands,\n",
      "Awaiting fate, with hopeful hands,\n",
      "Awaiting fate, with hopeful hands.\n",
      "The ball hurtles in, a.\n",
      "The ball hurtles in, a blur of speed,\n",
      "Will it be a blur of speed,\n",
      "Will it be a six, or a gentle deed?\n",
      "\n",
      "The six, or a gentle deed?\n",
      "\n",
      "The fielders wait, with eyes so keen fielders wait, with eyes so keen,\n",
      "For a catch to make, a,\n",
      "For a catch to make, a wicket to glean.\n",
      "The umpire wicket to glean.\n",
      "The umpire watches, with careful eye,\n",
      "As the watches, with careful eye,\n",
      "As the game unwinds, like a tale to game unwinds, like a tale to the sky.\n",
      "\n",
      "The crowd cheers on, the sky.\n",
      "\n",
      "The crowd cheers on, with joyful sound,\n",
      "As heroes rise, with joyful sound,\n",
      "As heroes rise, and legends are found.\n",
      "The thrill of and legends are found.\n",
      "The thrill of victory, the agony of defeat,\n",
      "Cr victory, the agony of defeat,\n",
      "Cricket's drama, forever to repeat.\n",
      "\n",
      "icket's drama, forever to repeat.\n",
      "\n",
      "From Ashes to T20, fromFrom Ashes to T20, from Test to One-Day,\n",
      "The game's Test to One-Day,\n",
      "The game's diversity, in every way.\n",
      "A global diversity, in every way.\n",
      "A global passion, that knows no bounds,\n",
      "Cr passion, that knows no bounds,\n",
      "Cricket's love, forever resounds.\n",
      "\n",
      "icket's love, forever resounds.\n",
      "\n",
      "So let us cherish, this noble gameSo let us cherish, this noble game,\n",
      "With all its charm, and its,\n",
      "With all its charm, and its storied fame.\n",
      "For in the cre storied fame.\n",
      "For in the crease, we find our peace,\n",
      "Inase, we find our peace,\n",
      "In cricket's world, our hearts release. cricket's world, our hearts release."
     ]
    }
   ],
   "source": [
    "for chunk in llm2.stream(\"I love cricket ! Write a poem about it. \"):\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bda7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
